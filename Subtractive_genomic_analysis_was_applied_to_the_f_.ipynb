{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nibaskumar93n-debug/Morphoinformatics/blob/main/Subtractive_genomic_analysis_was_applied_to_the_f_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing the **entire subtractive genomic analysis pipeline** as describedâ€”from protein sequence retrieval through essentiality and metabolic pathway analysis to subcellular localizationâ€”**is generally not feasible to execute *entirely* within a Google Colab notebook using the *exact* external web servers mentioned (UniProt, CD-HIT, BLASTp via NCBI web interface, Geptop, KAAS)**.\n",
        "\n",
        "However, **it is absolutely possible to replicate the *steps* and perform *equivalent analyses* using Python libraries and command-line tools that can be installed or run within the Colab environment**, though this requires significant coding and setup.\n",
        "\n",
        "Here is a guide outlining the feasibility and detailing the steps for a **Colab-adapted implementation**.\n",
        "\n",
        "-----\n",
        "\n",
        "## 1\\. Feasibility of Colab Implementation\n",
        "\n",
        "| Step | Original Tool | Feasibility in Colab | Notes on Colab Implementation |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Protein Retrieval** | UniProt Database | **High** | Use **BioPython** to fetch sequences using accession IDs or use UniProt's API. |\n",
        "| **Paralog Discarding** | CD-HIT Server | **High** | Install and run **CD-HIT** (command-line version) in Colab's terminal, or use a Python wrapper if available, or write a custom clustering script using a library like `scikit-learn` or `MMseqs2`. |\n",
        "| **Non-Homologous Identification** | BLASTp (NCBI Web) | **Medium/High** | Use **standalone BLAST+** (easily installed in Colab) and the **BioPython** `NcbiWWW` or `NcbiDblocal` modules. Requires downloading a human proteome database. **This is the most computationally intensive step.** |\n",
        "| **Essentiality Assessment** | Geptop Server | **Low** | Geptop is a proprietary web server. **Cannot be run directly.** You'd need to find a similar **essential gene prediction tool** (e.g., using machine learning models or comparative genomics data) or use a dataset of known essential genes if available. This step is the **hardest to replicate precisely.** |\n",
        "| **Metabolic Pathway Analysis** | KAAS Server | **Low** | KAAS is a specialized web server. **Cannot be run directly.** You would use **BioPython** and the **KEGG REST API** (or similar tools like **GhostKOALA** if they offer an API/standalone version) to assign KOs and map to pathways. This requires careful parsing of results. |\n",
        "| **Subcellular Localization** | (Tool not specified) | **Medium** | Use publicly available **standalone localization prediction tools** like **PSORTb** or **DeepTMHMM** (if available for install) or use an **API** from a service like **DeepLoc** (if one exists). |\n",
        "\n",
        "-----\n",
        "\n",
        "## 2\\. Step-by-Step Guide for Colab-Adapted Subtractive Genomic Analysis\n",
        "\n",
        "### A. Setup and Dependencies\n",
        "\n",
        "The first cell in your Colab notebook will be for installation."
      ],
      "metadata": {
        "id": "SzTW8WuT4uvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q biopython pandas requests\n",
        "!mkdir -p /content/{proteome,non_paralogous,blast_results}\n",
        "import requests, os, pandas as pd\n",
        "from Bio import SeqIO"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.3/3.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/3.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "jvZpSIyG4uvz",
        "outputId": "4f14ee44-83e8-4443-f540-48443a59e7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### B. Protein Sequence Retrieval (UniProt)\n",
        "\n",
        "Use **BioPython** to fetch the sequences for your four organisms."
      ],
      "metadata": {
        "id": "YHtGK7RP4uv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 1: Upload your proteome ---\n",
        "species_name = \"Bacteroides_uniformis\"\n",
        "uploaded_proteome = \"/content/proteome/Bacteroides_uniformis.fasta\"\n",
        "\n",
        "if os.path.exists(uploaded_proteome):\n",
        "    os.rename(uploaded_proteome, f\"/content/proteome/{species_name}.fasta\")\n",
        "    proteome_path = f\"/content/proteome/{species_name}.fasta\"\n",
        "    print(f\"âœ… Proteome uploaded: {proteome_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"âŒ Please upload your FASTA file manually in Colab first!\")\n",
        "\n",
        "# --- Count total proteins ---\n",
        "total_proteins = sum(1 for _ in SeqIO.parse(proteome_path, \"fasta\"))\n",
        "print(f\"ðŸ§© Total proteins in proteome: {total_proteins}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Proteome uploaded: /content/proteome/Bacteroides_uniformis.fasta\n",
            "ðŸ§© Total proteins in proteome: 4618\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofGmuMOx4uv1",
        "outputId": "06d779ed-93f5-4faf-c8fa-675b71a16684"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C. Paralog Discarding (CD-HIT)\n",
        "\n",
        "Run the **CD-HIT** command-line tool within Colab using the `!` prefix."
      ],
      "metadata": {
        "id": "PxAieQhp4uv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 2. Remove paralogous sequences using CD-HIT (60% identity)\n",
        "!apt-get install -y cd-hit\n",
        "\n",
        "# --- STEP 2: Remove paralogs using CD-HIT (60% identity) ---\n",
        "non_paralog_path = f\"/content/non_paralogous/{species_name}_nonparalog.fasta\"\n",
        "os.makedirs(\"/content/non_paralogous\", exist_ok=True)\n",
        "!cd-hit -i \"$proteome_path\" -o \"$non_paralog_path\" -c 0.6 -n 4 -d 0 > /dev/null\n",
        "\n",
        "# --- Count after CD-HIT ---\n",
        "non_paralog_count = sum(1 for _ in SeqIO.parse(non_paralog_path, \"fasta\"))\n",
        "print(f\"ðŸ§¬ Non-paralogous proteins retained: {non_paralog_count} ({(non_paralog_count/total_proteins)*100:.1f}% retained)\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  cd-hit\n",
            "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 521 kB of archives.\n",
            "After this operation, 1,082 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cd-hit amd64 4.8.1-4 [521 kB]\n",
            "Fetched 521 kB in 0s (2,452 kB/s)\n",
            "Selecting previously unselected package cd-hit.\n",
            "(Reading database ... 125082 files and directories currently installed.)\n",
            "Preparing to unpack .../cd-hit_4.8.1-4_amd64.deb ...\n",
            "Unpacking cd-hit (4.8.1-4) ...\n",
            "Setting up cd-hit (4.8.1-4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "ðŸ§¬ Non-paralogous proteins retained: 4419 (95.7% retained)\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQMhvjoy4uv2",
        "outputId": "4d1cab2b-e36a-4de4-cda2-82771f388cbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3: Remove human homologs ---\n",
        "\n",
        "# 3a. Install BLAST+\n",
        "!apt-get install -y ncbi-blast+ > /dev/null\n",
        "# 3a. Download human reference proteome (UniProt)\n",
        "!wget -q -O /content/human.fasta \"https://rest.uniprot.org/uniprotkb/stream?query=proteome:UP000005640&format=fasta\"\n",
        "\n",
        "# 3b. Build human BLAST database\n",
        "!makeblastdb -in /content/human.fasta -dbtype prot -out /content/human_db > /dev/null\n",
        "\n",
        "# 3c. Run BLASTp vs human\n",
        "blast_out = f\"/content/blast_results/{species_name}_vs_human.tsv\"\n",
        "os.makedirs(\"/content/blast_results\", exist_ok=True)\n",
        "!blastp -query \"$non_paralog_path\" -db /content/human_db -outfmt \"6 qseqid sseqid pident evalue qcovs\" -evalue 1e-5 -num_threads 2 -out \"$blast_out\"\n",
        "\n",
        "print(\"âœ… BLASTp vs Human completed.\")\n",
        "\n",
        "# --- 3d. Filter for non-homologous proteins (â‰¤30% identity, â‰¥70% coverage) ---\n",
        "df_human = pd.read_csv(blast_out, sep=\"\\t\", names=[\"qseqid\",\"sseqid\",\"pident\",\"evalue\",\"qcovs\"])\n",
        "human_homologs = set(df_human[(df_human[\"pident\"] > 30) & (df_human[\"qcovs\"] >= 70)][\"qseqid\"])\n",
        "non_homologous_ids = []\n",
        "\n",
        "for record in SeqIO.parse(non_paralog_path, \"fasta\"):\n",
        "    if record.id not in human_homologs:\n",
        "        non_homologous_ids.append(record.id)\n",
        "\n",
        "print(f\"ðŸš« Human-homologous proteins removed: {len(human_homologs)}\")\n",
        "print(f\"âœ… Non-homologous proteins retained: {len(non_homologous_ids)} ({(len(non_homologous_ids)/non_paralog_count)*100:.1f}% retained)\")\n",
        "\n",
        "# --- Save non-homologous FASTA ---\n",
        "non_hom_fasta = f\"/content/{species_name}_nonhomolog.fasta\"\n",
        "with open(non_hom_fasta, \"w\") as out:\n",
        "    for record in SeqIO.parse(non_paralog_path, \"fasta\"):\n",
        "        if record.id in non_homologous_ids:\n",
        "            SeqIO.write(record, out, \"fasta\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… BLASTp vs Human completed.\n",
            "ðŸš« Human-homologous proteins removed: 335\n",
            "âœ… Non-homologous proteins retained: 4084 (92.4% retained)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy3768l04uv2",
        "outputId": "f1bf9f1b-c21d-4017-f99e-36951b1de28a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip DEG10\n",
        "!gunzip -c /content/DEG10.aa.gz > /content/DEG10.aa.fasta\n"
      ],
      "metadata": {
        "id": "v9aTXMzod6y0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 4: Predict essential proteins using DEG10 ---\n",
        "!makeblastdb -in /content/DEG10.aa.fasta -dbtype prot -out /content/deg10_db > /dev/null\n",
        "\n",
        "blast_deg_out = f\"/content/{species_name}_vs_deg10.tsv\"\n",
        "!blastp -query \"$non_hom_fasta\" -db /content/deg10_db -outfmt \"6 qseqid sseqid pident evalue qcovs bitscore\" -evalue 1e-5 -num_threads 2 -out \"$blast_deg_out\"\n",
        "\n",
        "print(\"âœ… BLASTp vs DEG10 completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbeT_IsggiA-",
        "outputId": "d376212d-bd6f-4214-b071-28616fb6ea24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 91713: 44\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 102730: 48\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 110967: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 112557: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 112604: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 112775: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113161: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113389: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113405: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113418: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113681: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 113850: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 114182: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 114184: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 114210: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 114576: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 114656: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 115437: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 115649: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 115750: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 115807: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 115969: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 116269: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 116444: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 118396: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 118477: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125489: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125808: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125859: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125861: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125863: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125926: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 125951: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126109: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126117: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126203: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126242: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126632: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 126645: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 127103: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 127382: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 127714: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 128073: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 128183: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 128614: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 128778: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 128812: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 130778: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 130780: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 130782: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 130967: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131009: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131044: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131769: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131771: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131773: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131775: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131777: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131798: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131800: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131802: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 131804: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 136996: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 141963: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 142334: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 142788: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 143629: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 143670: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144301: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144393: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144401: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144601: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144609: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 144617: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 146667: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 146669: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 146675: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 146815: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 146995: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147187: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147225: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147271: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147289: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147337: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147407: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147541: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147747: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147768: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147794: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147889: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147985: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 147987: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148034: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148036: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148038: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148299: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148375: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148480: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148614: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148630: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148640: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148642: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148709: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148711: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 148989: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149029: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149076: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149524: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149526: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149555: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149557: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149559: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149567: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149592: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149632: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149634: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149779: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149781: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149834: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149903: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 149936: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150071: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150090: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150095: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150100: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150126: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150152: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150407: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150502: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150799: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150866: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150898: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150926: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150977: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150979: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 150981: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 151034: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 151087: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158896: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158898: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158900: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158902: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158904: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158906: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158908: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158910: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158912: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158914: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158916: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158918: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158920: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158922: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158924: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158926: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158928: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158930: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158932: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158934: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158936: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158938: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158940: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158942: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158944: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158946: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158948: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158950: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158952: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158954: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158956: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158958: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158960: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158962: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158964: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158966: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158968: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158970: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158972: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158974: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158976: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158978: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158980: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158982: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158984: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158986: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158988: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158990: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158992: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158994: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158996: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 158998: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159000: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159002: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159004: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159006: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159008: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159010: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159012: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159014: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159016: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159018: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159020: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159022: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159024: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159026: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159028: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159030: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159032: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159034: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159036: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159038: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159040: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159042: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159044: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159046: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159048: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159050: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159052: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159054: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159056: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159058: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159060: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159062: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159064: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159066: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159068: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159070: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159072: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159074: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159076: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159078: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159080: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159082: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159084: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159086: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159088: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159090: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159092: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159094: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159096: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159098: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159100: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159102: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159104: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159106: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159108: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159110: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159112: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159114: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159116: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159118: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159120: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159122: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159124: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159126: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159128: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159130: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159132: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159134: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159136: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159138: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159140: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159142: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159144: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159146: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159148: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159150: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159152: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159154: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159156: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159158: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159160: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159162: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159164: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159166: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159168: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159170: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159172: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159174: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159176: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159178: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159180: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159182: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159184: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159186: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159188: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159190: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159192: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159194: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159196: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159198: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159783: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 159951: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160062: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160064: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160368: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160379: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160451: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 160604: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 161398: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 161439: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 161502: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 161780: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 161885: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 162258: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 162527: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 162529: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 162623: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167292: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167445: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167451: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167453: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167455: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167519: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167532: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167536: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167540: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167557: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 167559: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 171318: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 180917: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 181799: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 181878: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 181989: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 181997: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 182092: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 182922: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 183024: 18\n",
            "FASTA-Reader: Ignoring invalid residues at position(s): On line 183831: 18\n",
            "âœ… BLASTp vs DEG10 completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 5: Filter essential-like hits (GEPTOP mimic logic) ---\n",
        "df_deg = pd.read_csv(blast_deg_out, sep=\"\\t\", names=[\"qseqid\",\"sseqid\",\"pident\",\"evalue\",\"qcovs\",\"bitscore\"])\n",
        "filtered = df_deg[(df_deg[\"pident\"] >= 30) & (df_deg[\"qcovs\"] >= 70)]\n",
        "\n",
        "# Keep only best hit per query\n",
        "best_hits = filtered.sort_values(\"evalue\").drop_duplicates(\"qseqid\", keep=\"first\")\n",
        "\n",
        "print(f\"â­ Total DEG10 hits passing threshold: {len(filtered)}\")\n",
        "print(f\"ðŸŽ¯ Unique predicted essential proteins: {len(best_hits)} ({(len(best_hits)/len(non_homologous_ids))*100:.1f}% of non-homologous proteins)\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64bMtmZg6_T",
        "outputId": "fbd5817a-e761-4647-ab55-3eeca1670c00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â­ Total DEG10 hits passing threshold: 8676\n",
            "ðŸŽ¯ Unique predicted essential proteins: 1014 (24.8% of non-homologous proteins)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # --- STEP 5: Filter essential-like hits (stricter GEPTOP mimic logic) ---Getting too many essential proteins so using stricter threshold\n",
        "df_deg = pd.read_csv(blast_deg_out, sep=\"\\t\", names=[\"qseqid\",\"sseqid\",\"pident\",\"evalue\",\"qcovs\",\"bitscore\"])\n",
        "\n",
        "# âœ… Tightened thresholds for higher confidence\n",
        "filtered = df_deg[\n",
        "    (df_deg[\"pident\"] >= 40) &\n",
        "    (df_deg[\"qcovs\"] >= 80) &\n",
        "    (df_deg[\"bitscore\"] >= 100) &\n",
        "    (df_deg[\"evalue\"] <= 1e-10)\n",
        "]\n",
        "\n",
        "# Keep only the best hit per protein\n",
        "best_hits = filtered.sort_values(\"evalue\").drop_duplicates(\"qseqid\", keep=\"first\")\n",
        "\n",
        "print(f\"â­ Total DEG10 hits passing strict threshold: {len(filtered)}\")\n",
        "print(f\"ðŸŽ¯ Unique predicted essential proteins: {len(best_hits)} ({(len(best_hits)/len(non_homologous_ids))*100:.1f}% of non-homologous proteins)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcVGyFv8ksfF",
        "outputId": "945f4366-207e-4df9-d65d-b2f4e1295dce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â­ Total DEG10 hits passing strict threshold: 3431\n",
            "ðŸŽ¯ Unique predicted essential proteins: 607 (14.9% of non-homologous proteins)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Extract FASTA for essential proteins ---\n",
        "ids_to_keep = set(best_hits[\"qseqid\"])\n",
        "output_fasta = f\"/content/{species_name}_predicted_essential.fasta\"\n",
        "\n",
        "with open(output_fasta, \"w\") as out:\n",
        "    for record in SeqIO.parse(non_hom_fasta, \"fasta\"):\n",
        "        if record.id in ids_to_keep:\n",
        "            SeqIO.write(record, out, \"fasta\")\n",
        "\n",
        "print(f\"ðŸ’¾ FASTA saved: {output_fasta}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0VcfqFgg_-e",
        "outputId": "12f82f7c-e18a-4e39-efd6-de1557484ff0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ FASTA saved: /content/Bacteroides_uniformis_predicted_essential.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 6: Extract FASTA for essential proteins ---\n",
        "ids_to_keep = set(best_hits[\"qseqid\"])\n",
        "output_fasta = f\"/content/{species_name}_predicted_essential_revised_threshold.fasta\"\n",
        "\n",
        "with open(output_fasta, \"w\") as out:\n",
        "    for record in SeqIO.parse(non_hom_fasta, \"fasta\"):\n",
        "        if record.id in ids_to_keep:\n",
        "            SeqIO.write(record, out, \"fasta\")\n",
        "\n",
        "print(f\"ðŸ’¾ FASTA saved: {output_fasta}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOuA9ZfXpcKb",
        "outputId": "8bbb30bb-44f8-49c4-d609-08613ec978b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ’¾ FASTA saved: /content/Bacteroides_uniformis_predicted_essential_revised_threshold.fasta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1ï¸âƒ£ Load KAAS mapping (protein â†’ KO)\n",
        "kaas_file = \"/content/Kaas_bacteroides_uniformis.csv\"  # your CSV file\n",
        "\n",
        "# Read as standard CSV (comma-separated)\n",
        "df = pd.read_csv(kaas_file)\n",
        "\n",
        "# Check column names\n",
        "print(\"Columns detected:\", df.columns.tolist())\n",
        "if not {\"protein\", \"KO\"}.issubset(df.columns):\n",
        "    df.columns = [\"protein\", \"KO\"]  # enforce standard naming if not present\n",
        "\n",
        "# 2ï¸âƒ£ Count assigned and unassigned\n",
        "assigned = df[\"KO\"].notna().sum()\n",
        "unassigned = df[\"KO\"].isna().sum()\n",
        "print(f\"Assigned KO IDs: {assigned}\")\n",
        "print(f\"Unassigned proteins: {unassigned}\")\n",
        "\n",
        "# 3ï¸âƒ£ Remove NA and get unique KO IDs\n",
        "ko_list = df[\"KO\"].dropna().unique().tolist()\n",
        "\n",
        "# 4ï¸âƒ£ Map each KO to KEGG pathways via KEGG REST API\n",
        "def get_pathways_for_ko(ko):\n",
        "    url = f\"https://rest.kegg.jp/link/pathway/ko:{ko}\"\n",
        "    res = requests.get(url)\n",
        "    if res.status_code == 200:\n",
        "        lines = res.text.strip().split(\"\\n\")\n",
        "        pathways = []\n",
        "        for l in lines:\n",
        "            parts = l.split(\"\\t\")\n",
        "            if len(parts) > 1:  # only if both columns exist\n",
        "                pathways.append(parts[1].replace(\"path:\", \"\"))\n",
        "        return pathways\n",
        "    return []\n",
        "\n",
        "\n",
        "ko_to_path = {}\n",
        "for ko in tqdm(ko_list, desc=\"Mapping KO â†’ Pathway\"):\n",
        "    ko_to_path[ko] = get_pathways_for_ko(ko)\n",
        "\n",
        "# 5ï¸âƒ£ Create DataFrame of KO â†’ Pathway\n",
        "path_df = (\n",
        "    pd.DataFrame([(ko, p) for ko, plist in ko_to_path.items() for p in plist],\n",
        "                 columns=[\"KO\", \"Pathway\"])\n",
        ")\n",
        "\n",
        "# 6ï¸âƒ£ Identify KO IDs with no pathway mapping\n",
        "mapped_kos = set(path_df[\"KO\"])\n",
        "unmapped_kos = [ko for ko in ko_list if ko not in mapped_kos]\n",
        "print(f\"\\nKO-assigned proteins with NO pathway mapping: {len(unmapped_kos)}\")\n",
        "\n",
        "# 7ï¸âƒ£ Download human pathway list\n",
        "human_pathways = requests.get(\"http://rest.kegg.jp/list/pathway/hsa\").text\n",
        "human_path_list = [line.split(\"\\t\")[0].replace(\"path:\", \"\") for line in human_pathways.strip().split(\"\\n\")]\n",
        "\n",
        "# 8ï¸âƒ£ Identify shared vs unique bacterial pathways\n",
        "path_df[\"Shared_with_Human\"] = path_df[\"Pathway\"].isin(human_path_list)\n",
        "\n",
        "shared = path_df[path_df[\"Shared_with_Human\"]].Pathway.nunique()\n",
        "unique = path_df[~path_df[\"Shared_with_Human\"]].Pathway.nunique()\n",
        "\n",
        "print(f\"\\nðŸ§­ Pathway summary:\")\n",
        "print(f\"Total distinct pathways: {path_df.Pathway.nunique()}\")\n",
        "print(f\"Shared with Human: {shared}\")\n",
        "print(f\"Unique bacterial: {unique}\")\n",
        "\n",
        "# 9ï¸âƒ£ Save results\n",
        "path_df.to_csv(\"/content/KAAS_pathway_analysis.csv\", index=False)\n",
        "print(\"\\nâœ… Results saved to: /content/KAAS_pathway_analysis.csv\")\n",
        "\n",
        "# ðŸ”Ÿ Save unique bacterial pathways only\n",
        "unique_df = path_df[~path_df[\"Shared_with_Human\"]]\n",
        "unique_df.to_csv(\"/content/unique_bacterial_pathways.csv\", index=False)\n",
        "print(\"ðŸ§¬ Unique bacterial pathways saved: /content/unique_bacterial_pathways.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFd-6YQ2njkL",
        "outputId": "551ec5c9-ddc9-4a42-bdf6-c513775be53c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns detected: ['Protein', 'KO']\n",
            "Assigned KO IDs: 415\n",
            "Unassigned proteins: 192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Mapping KO â†’ Pathway: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 402/402 [04:59<00:00,  1.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KO-assigned proteins with NO pathway mapping: 118\n",
            "\n",
            "ðŸ§­ Pathway summary:\n",
            "Total distinct pathways: 222\n",
            "Shared with Human: 0\n",
            "Unique bacterial: 222\n",
            "\n",
            "âœ… Results saved to: /content/KAAS_pathway_analysis.csv\n",
            "ðŸ§¬ Unique bacterial pathways saved: /content/unique_bacterial_pathways.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Input files ---\n",
        "kaas_file = \"/content/Kaas_bacteroides_uniformis.csv\"      # Protein â†’ KO mapping (comma-delimited)\n",
        "pathway_file = \"/content/KAAS_pathway_analysis.csv\"      # KO â†’ Pathway mapping (comma-delimited)\n",
        "\n",
        "# --- Load data ---\n",
        "mapping_df = pd.read_csv(kaas_file)  # uses header from file\n",
        "path_df = pd.read_csv(pathway_file)\n",
        "\n",
        "# --- Summary: Assigned vs Unassigned KOs ---\n",
        "assigned = mapping_df[\"KO\"].notna().sum()\n",
        "unassigned = mapping_df[\"KO\"].isna().sum()\n",
        "\n",
        "# --- KO â†’ pathway mapping ---\n",
        "ko_list = mapping_df[\"KO\"].dropna().unique().tolist()\n",
        "ko_with_no_pathway = [ko for ko in ko_list if ko not in path_df[\"KO\"].unique()]\n",
        "num_no_pathway = len(ko_with_no_pathway)\n",
        "\n",
        "# --- Filter only unique bacterial pathways ---\n",
        "unique_pathways_df = path_df[path_df[\"Shared_with_Human\"] == False]\n",
        "\n",
        "# --- Merge protein â†’ KO with KO â†’ pathway ---\n",
        "merged_df = pd.merge(mapping_df.dropna(subset=[\"KO\"]), unique_pathways_df, on=\"KO\", how=\"inner\")\n",
        "merged_df = merged_df.drop_duplicates(subset=[\"Protein\", \"KO\", \"Pathway\"])\n",
        "\n",
        "# --- Save merged protein â†’ KO â†’ pathway CSV ---\n",
        "output_file = \"/content/Bacteroides_uniformis_merged_information.csv\"\n",
        "merged_df.to_csv(output_file, index=False)\n",
        "\n",
        "# --- Save summary info ---\n",
        "summary_file = \"/content/Bacteroides_uniformis_KO_summary.csv\"\n",
        "summary_df = pd.DataFrame({\n",
        "    \"Metric\": [\"Assigned KO IDs\", \"Unassigned proteins\", \"KO-assigned proteins with NO pathway mapping\",\n",
        "               \"Total distinct pathways\", \"Shared with Human\", \"Unique bacterial pathways\"],\n",
        "    \"Count\": [assigned, unassigned, num_no_pathway,\n",
        "              path_df[\"Pathway\"].nunique(), path_df[path_df[\"Shared_with_Human\"]].Pathway.nunique(),\n",
        "              unique_pathways_df.Pathway.nunique()]\n",
        "})\n",
        "summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "# --- Print info ---\n",
        "print(f\"âœ… Merged protein â†’ KO â†’ pathway file saved: {output_file}\")\n",
        "print(f\"âœ… Summary file saved: {summary_file}\")\n",
        "print(summary_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW7V7W7ykSXS",
        "outputId": "a29cbe2f-9df0-4ce3-800c-4a1ee72efcec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Merged protein â†’ KO â†’ pathway file saved: /content/Bacteroides_uniformis_merged_information.csv\n",
            "âœ… Summary file saved: /content/Bacteroides_uniformis_KO_summary.csv\n",
            "                                         Metric  Count\n",
            "0                               Assigned KO IDs    415\n",
            "1                           Unassigned proteins    192\n",
            "2  KO-assigned proteins with NO pathway mapping    118\n",
            "3                       Total distinct pathways    222\n",
            "4                             Shared with Human      0\n",
            "5                     Unique bacterial pathways    222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Load KAAS results (protein â†” KO) ---\n",
        "kaas_df = pd.read_csv(\"/content/Kaas_bacteroides_uniformis.csv\")\n",
        "\n",
        "# --- Load KO â†” Pathway data (from your previous analysis) ---\n",
        "path_df = pd.read_csv(\"/content/KAAS_pathway_analysis.csv\")\n",
        "\n",
        "# --- Filter for unique bacterial pathways ---\n",
        "unique_df = path_df[path_df[\"Shared_with_Human\"] == False]\n",
        "\n",
        "# --- Get list of unique KO IDs ---\n",
        "unique_kos = unique_df[\"KO\"].unique()\n",
        "\n",
        "# --- Subset proteins belonging to those KOs ---\n",
        "unique_proteins = kaas_df[kaas_df[\"KO\"].isin(unique_kos)]\n",
        "\n",
        "# --- Save list of unique proteins ---\n",
        "unique_proteins.to_csv(\"/content/Bacteroides_uniformis_unique_pathway_proteins.csv\", index=False)\n",
        "print(f\"âœ… Unique proteins saved: {unique_proteins.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sppFBa0UUa7Z",
        "outputId": "900c302c-35c8-4905-fd1a-f83d29abf2e0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Unique proteins saved: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "import pandas as pd\n",
        "\n",
        "# --- INPUT FILES ---\n",
        "fasta_file = \"/content/Bacteroides_uniformis_predicted_essential_revised_threshold.fasta\"\n",
        "pathway_file = \"/content/KAAS_pathway_analysis.csv\"\n",
        "mapping_file = \"/content/Kaas_bacteroides_uniformis.csv\"\n",
        "\n",
        "# --- LOAD DATA ---\n",
        "path_df = pd.read_csv(pathway_file)\n",
        "mapping_df = pd.read_csv(mapping_file, sep=\",\")  # ðŸ‘ˆ changed from '\\t' to ','\n",
        "\n",
        "# Ensure column names are correct\n",
        "mapping_df.columns = [\"protein\", \"KO\"]\n",
        "\n",
        "# Get KOs that are NOT shared with human (unique bacterial)\n",
        "unique_kos = path_df.loc[path_df[\"Shared_with_Human\"] == False, \"KO\"].unique().tolist()\n",
        "\n",
        "# Get protein IDs associated with those unique KOs\n",
        "unique_proteins = mapping_df[mapping_df[\"KO\"].isin(unique_kos)][\"protein\"].unique().tolist()\n",
        "\n",
        "print(f\"âœ… Unique bacterial KOs: {len(unique_kos)}\")\n",
        "print(f\"âœ… Corresponding protein IDs: {len(unique_proteins)}\")\n",
        "\n",
        "# --- FILTER FASTA ---\n",
        "output_fasta = \"/content/Bacteroides_uniformis_unique_pathway_proteins.fasta\"\n",
        "count = 0\n",
        "\n",
        "with open(output_fasta, \"w\") as out_f:\n",
        "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "        if any(pid in record.id for pid in unique_proteins):\n",
        "            SeqIO.write(record, out_f, \"fasta\")\n",
        "            count += 1\n",
        "\n",
        "print(f\"ðŸŽ¯ Unique-pathway protein sequences saved: {output_fasta}\")\n",
        "print(f\"Total sequences written: {count}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7vzOx-XpxY0",
        "outputId": "e2e15148-1f40-4eff-f951-809a7d80d05d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Unique bacterial KOs: 284\n",
            "âœ… Corresponding protein IDs: 291\n",
            "ðŸŽ¯ Unique-pathway protein sequences saved: /content/Bacteroides_uniformis_unique_pathway_proteins.fasta\n",
            "Total sequences written: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Path to your PSORTb CSV\n",
        "psortb_csv = \"/content/PSORTb_results.csv\"\n",
        "\n",
        "# Read as plain text (since all info is in one column)\n",
        "df_raw = pd.read_csv(psortb_csv, header=None, names=[\"Text\"], dtype=str)\n",
        "print(f\"âœ… Loaded {len(df_raw)} rows from PSORTb result\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPWVB0N_PkGl",
        "outputId": "84bab9a0-8134-4cb9-b50d-ec538ba79fc9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 7275 rows from PSORTb result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load your raw PSORTb results (text in one column)\n",
        "df_raw = pd.read_csv(\"/content/PSORTb_results.csv\")  # change filename if needed\n",
        "\n",
        "# Join all rows into one large text block\n",
        "content = \"\\n\".join(df_raw.iloc[:,0].tolist())\n",
        "\n",
        "# Split by \"SeqID:\"\n",
        "entries = re.split(r\"SeqID:\", content)\n",
        "records = []\n",
        "\n",
        "for entry in entries:\n",
        "    entry = entry.strip()\n",
        "    if not entry:\n",
        "        continue\n",
        "\n",
        "    # Extract the sequence ID\n",
        "    seq_match = re.search(r\"^\\s*(\\S+)\", entry)\n",
        "\n",
        "    # Extract the final prediction localization\n",
        "    loc_match = re.search(r\"Final Prediction:\\s*(\\w+)\", entry)\n",
        "\n",
        "    if seq_match and loc_match:\n",
        "        seqid = seq_match.group(1).strip()\n",
        "        loc = loc_match.group(1).strip()\n",
        "        records.append((seqid, loc))\n",
        "\n",
        "# Create a dataframe\n",
        "df = pd.DataFrame(records, columns=[\"SeqID\", \"Localization\"])\n",
        "\n",
        "# Save the cleaned file\n",
        "df.to_csv(\"/content/psortb_cleaned.csv\", index=False)\n",
        "\n",
        "print(f\"âœ… Extracted {len(df)} protein predictions\")\n",
        "print(\"ðŸ’¾ Saved as: /content/psortb_cleaned.csv\")\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "nz_aIQK4QpST",
        "outputId": "180b8e7f-18b4-4279-a703-464b392a1909"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "sequence item 21: expected str instance, float found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-243043763.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Join all rows into one large text block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Split by \"SeqID:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sequence item 21: expected str instance, float found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your PSORTb results\n",
        "df = pd.read_csv(\"/content/psortb_cleaned.csv\")\n",
        "\n",
        "# Normalize localization text to lowercase and strip whitespace\n",
        "df[\"Localization\"] = df[\"Localization\"].str.lower().str.strip()\n",
        "\n",
        "# ðŸ§ª Cytoplasmic ONLY (exclude cytoplasmic membrane)\n",
        "cytoplasmic_only = df[df[\"Localization\"] == \"cytoplasmic\"]\n",
        "\n",
        "# ðŸ§¬ Cytoplasmic Membrane\n",
        "cytoplasmic_membrane = df[\n",
        "    df[\"Localization\"].str.contains(\n",
        "        \"cytoplasmicmembrane|cytoplasmic membrane\",\n",
        "        case=False,\n",
        "        na=False\n",
        "    )\n",
        "]\n",
        "\n",
        "# ðŸ’‰ Vaccine candidates (outer membrane, extracellular, periplasmic)\n",
        "vaccine_candidates = df[\n",
        "    df[\"Localization\"].str.contains(\n",
        "        \"outermembrane|outer membrane|extracellular|periplasm\",\n",
        "        case=False,\n",
        "        na=False\n",
        "    )\n",
        "]\n",
        "\n",
        "# â“ Unknown localization\n",
        "unknown_localization = df[df[\"Localization\"] == \"unknown\"]\n",
        "\n",
        "# ðŸ“Š Print comprehensive summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ðŸ“Š SUBCELLULAR LOCALIZATION ANALYSIS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total proteins analyzed: {len(df)}\")\n",
        "print(f\"\\nðŸ”¬ Localization Distribution:\")\n",
        "print(f\"  ðŸ§ª Cytoplasmic only: {len(cytoplasmic_only)} ({len(cytoplasmic_only)/len(df)*100:.1f}%)\")\n",
        "print(f\"  ðŸ§¬ Cytoplasmic membrane: {len(cytoplasmic_membrane)} ({len(cytoplasmic_membrane)/len(df)*100:.1f}%)\")\n",
        "print(f\"  ðŸ’‰ Outer membrane/Extracellular/Periplasmic: {len(vaccine_candidates)} ({len(vaccine_candidates)/len(df)*100:.1f}%)\")\n",
        "print(f\"  â“ Unknown: {len(unknown_localization)} ({len(unknown_localization)/len(df)*100:.1f}%)\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# ðŸŽ¯ Drug target prioritization (following the paper's approach - keep all but categorize)\n",
        "print(f\"ðŸŽ¯ DRUG TARGET PRIORITIZATION:\")\n",
        "print(f\"  â­ High priority (membrane/secreted): {len(vaccine_candidates)} proteins\")\n",
        "print(f\"     â†’ Accessible, good for antibodies/small molecules\")\n",
        "print(f\"  â­ Medium priority (cytoplasmic membrane): {len(cytoplasmic_membrane)} proteins\")\n",
        "print(f\"     â†’ Targetable with membrane-permeable drugs\")\n",
        "print(f\"  â­ Lower priority (cytoplasmic): {len(cytoplasmic_only)} proteins\")\n",
        "print(f\"     â†’ Requires cell penetration, but still valid targets\")\n",
        "print(f\"  âš ï¸  Unknown localization: {len(unknown_localization)} proteins\")\n",
        "print(f\"     â†’ Needs further analysis\\n\")\n",
        "\n",
        "# Save all categories\n",
        "df.to_csv(\"/content/psortb_cleaned.csv\", index=False)\n",
        "cytoplasmic_only.to_csv(\"/content/cytoplasmic_only.csv\", index=False)\n",
        "cytoplasmic_membrane.to_csv(\"/content/cytoplasmic_membrane.csv\", index=False)\n",
        "vaccine_candidates.to_csv(\"/content/vaccine_candidates.csv\", index=False)\n",
        "unknown_localization.to_csv(\"/content/unknown_localization.csv\", index=False)\n",
        "\n",
        "# Combined drug targets (all except pure cytoplasmic if you want to be strict)\n",
        "# But following the paper - keep ALL\n",
        "all_targets = df.copy()\n",
        "all_targets.to_csv(\"/content/all_localized_targets.csv\", index=False)\n",
        "\n",
        "print(\"âœ… Files saved:\")\n",
        "print(\"  - psortb_cleaned.csv (all proteins)\")\n",
        "print(\"  - cytoplasmic_only.csv\")\n",
        "print(\"  - cytoplasmic_membrane.csv\")\n",
        "print(\"  - vaccine_candidates.csv\")\n",
        "print(\"  - unknown_localization.csv\")\n",
        "print(\"  - all_localized_targets.csv\")\n",
        "\n",
        "# ðŸ“ˆ Detailed breakdown\n",
        "print(f\"\\nðŸ“ˆ Detailed Localization Breakdown:\")\n",
        "print(df[\"Localization\"].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_yCvm8SSPaa",
        "outputId": "f3fa83c2-5f50-4144-d489-565faafb34f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ðŸ“Š SUBCELLULAR LOCALIZATION ANALYSIS\n",
            "============================================================\n",
            "Total proteins analyzed: 295\n",
            "\n",
            "ðŸ”¬ Localization Distribution:\n",
            "  ðŸ§ª Cytoplasmic only: 238 (80.7%)\n",
            "  ðŸ§¬ Cytoplasmic membrane: 37 (12.5%)\n",
            "  ðŸ’‰ Outer membrane/Extracellular/Periplasmic: 4 (1.4%)\n",
            "  â“ Unknown: 16 (5.4%)\n",
            "============================================================\n",
            "\n",
            "ðŸŽ¯ DRUG TARGET PRIORITIZATION:\n",
            "  â­ High priority (membrane/secreted): 4 proteins\n",
            "     â†’ Accessible, good for antibodies/small molecules\n",
            "  â­ Medium priority (cytoplasmic membrane): 37 proteins\n",
            "     â†’ Targetable with membrane-permeable drugs\n",
            "  â­ Lower priority (cytoplasmic): 238 proteins\n",
            "     â†’ Requires cell penetration, but still valid targets\n",
            "  âš ï¸  Unknown localization: 16 proteins\n",
            "     â†’ Needs further analysis\n",
            "\n",
            "âœ… Files saved:\n",
            "  - psortb_cleaned.csv (all proteins)\n",
            "  - cytoplasmic_only.csv\n",
            "  - cytoplasmic_membrane.csv\n",
            "  - vaccine_candidates.csv\n",
            "  - unknown_localization.csv\n",
            "  - all_localized_targets.csv\n",
            "\n",
            "ðŸ“ˆ Detailed Localization Breakdown:\n",
            "Localization\n",
            "cytoplasmic            238\n",
            "cytoplasmicmembrane     37\n",
            "unknown                 16\n",
            "periplasmic              3\n",
            "outermembrane            1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### For Gene_symbol from Uniprot\n",
        "\n",
        "ids = df[\"SeqID\"].dropna().unique().tolist()\n",
        "print(f\"Found {len(ids)} unique protein IDs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuOQb6c3zxse",
        "outputId": "aa8e4a6c-be68-4ea1-ae17-792176f43124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 295 unique protein IDs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def get_gene_name_from_uniprot(SeqID):\n",
        "    \"\"\"Fetch gene name from UniProt API\"\"\"\n",
        "    try:\n",
        "        # Clean protein ID (remove version numbers like .1, .2)\n",
        "        clean_id = SeqID.split('.')[0].split('|')[-1]\n",
        "\n",
        "        url = f\"https://rest.uniprot.org/uniprotkb/{clean_id}.json\"\n",
        "        response = requests.get(url, timeout=10)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            # Try to get gene name\n",
        "            if 'genes' in data and len(data['genes']) > 0:\n",
        "                if 'geneName' in data['genes'][0]:\n",
        "                    return data['genes'][0]['geneName']['value']\n",
        "\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Load cytoplasmic proteins\n",
        "df_cytoplasmic = pd.read_csv(\"/content/cytoplasmic_only.csv\")\n",
        "\n",
        "# Get gene names (this will take time - ~234 API calls)\n",
        "gene_names = []\n",
        "print(\"Fetching gene names from UniProt...\")\n",
        "\n",
        "for i, SeqID in enumerate(df_cytoplasmic['SeqID']):\n",
        "    gene_name = get_gene_name_from_uniprot(SeqID)\n",
        "    gene_names.append(gene_name if gene_name else SeqID)\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"  Processed {i + 1}/{len(df_cytoplasmic)} proteins...\")\n",
        "        time.sleep(0.5)  # Be nice to UniProt API\n",
        "\n",
        "df_cytoplasmic['Gene_Name'] = gene_names\n",
        "df_cytoplasmic.to_csv(\"/content/cytoplasmic_with_genes.csv\", index=False)\n",
        "print(\"âœ… Gene names retrieved and saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm8uPgNh0gAC",
        "outputId": "45124907-0f4a-4506-fac9-fc182a4e06b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching gene names from UniProt...\n",
            "  Processed 10/238 proteins...\n",
            "  Processed 20/238 proteins...\n",
            "  Processed 30/238 proteins...\n",
            "  Processed 40/238 proteins...\n",
            "  Processed 50/238 proteins...\n",
            "  Processed 60/238 proteins...\n",
            "  Processed 70/238 proteins...\n",
            "  Processed 80/238 proteins...\n",
            "  Processed 90/238 proteins...\n",
            "  Processed 100/238 proteins...\n",
            "  Processed 110/238 proteins...\n",
            "  Processed 120/238 proteins...\n",
            "  Processed 130/238 proteins...\n",
            "  Processed 140/238 proteins...\n",
            "  Processed 150/238 proteins...\n",
            "  Processed 160/238 proteins...\n",
            "  Processed 170/238 proteins...\n",
            "  Processed 180/238 proteins...\n",
            "  Processed 190/238 proteins...\n",
            "  Processed 200/238 proteins...\n",
            "  Processed 210/238 proteins...\n",
            "  Processed 220/238 proteins...\n",
            "  Processed 230/238 proteins...\n",
            "âœ… Gene names retrieved and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### using batch  to find gene symbol import requests### not very handy\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def batch_uniprot_mapping(SeqID):\n",
        "    \"\"\"Map multiple protein IDs to gene names in one request\"\"\"\n",
        "\n",
        "    # Prepare the mapping request\n",
        "    url = \"https://rest.uniprot.org/idmapping/run\"\n",
        "\n",
        "    params = {\n",
        "        'ids': ','.join(SeqID[:500]),  # Max 500 at a time\n",
        "        'from': 'UniProtKB_AC-ID',\n",
        "        'to': 'Gene_Name'\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, data=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        job_id = response.json()['jobId']\n",
        "\n",
        "        # Poll for results\n",
        "        results_url = f\"https://rest.uniprot.org/idmapping/status/{job_id}\"\n",
        "\n",
        "        for _ in range(30):  # Try for 30 seconds\n",
        "            time.sleep(1)\n",
        "            status = requests.get(results_url).json()\n",
        "\n",
        "            if 'results' in status:\n",
        "                return status['results']\n",
        "\n",
        "    return []\n",
        "\n",
        "# Use this for your 234 proteins\n",
        "df_cytoplasmic = pd.read_csv(\"/content/cytoplasmic_only.csv\")\n",
        "SeqID = df_cytoplasmic['SeqID'].tolist()\n",
        "\n",
        "# Clean IDs\n",
        "clean_ids = [pid.split('.')[0].split('|')[-1] for pid in SeqID]\n",
        "\n",
        "results = batch_uniprot_mapping(clean_ids[:500])  # First 500\n",
        "\n",
        "# Parse results\n",
        "id_to_gene = {r['from']: r['to'] for r in results}\n",
        "df_cytoplasmic['Gene_Name'] = df_cytoplasmic['SeqID'].apply(\n",
        "    lambda x: id_to_gene.get(x.split('.')[0].split('|')[-1], x)\n",
        ")\n",
        "\n",
        "# ðŸ’¾ Save output file\n",
        "output_path = \"/content/cytoplasmic_with_genes_batch.csv\"\n",
        "df_cytoplasmic.to_csv(output_path, index=False)\n",
        "print(f\"âœ… Output file saved to: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txnXDFUR4-H7",
        "outputId": "2ba394f7-a7dd-404c-b9ad-58c7bdca6948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Output file saved to: /content/cytoplasmic_with_genes_batch.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "\n",
        "input_fasta = \"/content/Bifidobacterium_animalis_unique_pathway_proteins.fasta\"\n",
        "records = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
        "\n",
        "chunk_size = 70\n",
        "for i in range(0, len(records), chunk_size):\n",
        "    chunk = records[i:i+chunk_size]\n",
        "    output_file = f\"/content/unique_proteins_chunk_{i//chunk_size + 1}.fasta\"\n",
        "    SeqIO.write(chunk, output_file, \"fasta\")\n",
        "    print(f\"âœ… Chunk saved: {output_file} ({len(chunk)} sequences)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy-0c8j5oHLN",
        "outputId": "05483769-0ad2-407e-d358-dd09f75996ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Chunk saved: /content/unique_proteins_chunk_1.fasta (70 sequences)\n",
            "âœ… Chunk saved: /content/unique_proteins_chunk_2.fasta (60 sequences)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### The NetGenes databse system is not clear to me now ,,, because there is no protein sequence onley the essential gene and their scores........\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Upload your NetGenes zip file\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8AOKZ0SSjIjw",
        "outputId": "db894a9d-ac45-45c3-86cb-5d41abe7d73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-31aa28af-1b27-4546-b4cf-107f8d2a59f5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-31aa28af-1b27-4546-b4cf-107f8d2a59f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving NetGenes.zip to NetGenes.zip\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}